# ğŸ‰ ä¸­æ–‡CLIPæ¨¡å‹ä¸‹è½½å®Œæˆ

**æ—¥æœŸ**: 2025-11-26
**çŠ¶æ€**: âœ… å…¨éƒ¨ä¸‹è½½å®Œæˆ

---

## ğŸ“¦ å·²ä¸‹è½½çš„æ¨¡å‹

### æ¨¡å‹1: CN-CLIP (OFA-Syså®˜æ–¹ç‰ˆ)

**ä½ç½®**: `assets/models/cn-clip/`
**æ¥æº**: OFA-Sys/chinese-clip-vit-base-patch16
**å¤§å°**: 719MB
**æ ¼å¼**: PyTorch

**æ–‡ä»¶æ¸…å•**:
```
cn-clip/
â”œâ”€â”€ pytorch_model.bin    719MB  âœ…  PyTorchæ¨¡å‹
â”œâ”€â”€ config.json           3.0KB âœ…  é…ç½®æ–‡ä»¶
â”œâ”€â”€ vocab.txt            107KB  âœ…  BERTè¯è¡¨ (21,128è¯)
â””â”€â”€ model_info.json      235B   âœ…  å…ƒä¿¡æ¯
```

**è§„æ ¼**:
- æ–‡æœ¬ç¼–ç å™¨: BERT-base-chinese
- å›¾åƒç¼–ç å™¨: ViT-B/16
- ç‰¹å¾ç»´åº¦: 512
- è¯­è¨€: ä¸­æ–‡ + è‹±æ–‡ï¼ˆåŒè¯­ï¼‰

---

### æ¨¡å‹2: CN-CLIP (eisneim ONNXç‰ˆ) ğŸŒŸ

**ä½ç½®**: `assets/models/cn-clip-eisneim/`
**æ¥æº**: eisneim/cn-clip_vit-b-16
**å¤§å°**: 1.1GB
**æ ¼å¼**: ONNX (å·²ä¼˜åŒ–ï¼Œå¯ç›´æ¥ä½¿ç”¨ï¼)

**æ–‡ä»¶æ¸…å•**:
```
cn-clip-eisneim/
â”œâ”€â”€ vit-b-16.img.fp32.onnx           333MB  âœ…  å›¾åƒç¼–ç å™¨ (FP32)
â”œâ”€â”€ vit-b-16.txt.fp32.onnx           392MB  âœ…  æ–‡æœ¬ç¼–ç å™¨ (FP32)
â”œâ”€â”€ vit-b-16.img.fp16.onnx          3.6MB  âœ…  å›¾åƒç¼–ç å™¨ (FP16)
â”œâ”€â”€ vit-b-16.img.fp16.onnx.extra    165MB  âœ…  FP16æƒé‡
â”œâ”€â”€ vit-b-16.txt.fp16.onnx          2.2MB  âœ…  æ–‡æœ¬ç¼–ç å™¨ (FP16)
â”œâ”€â”€ vit-b-16.txt.fp16.onnx.extra    195MB  âœ…  FP16æƒé‡
â””â”€â”€ README.md                        552B   âœ…  è¯´æ˜æ–‡æ¡£
```

**é‡è¦**: ğŸ **è¿™ä¸ªç‰ˆæœ¬å·²ç»æ˜¯ONNXæ ¼å¼ï¼Œå¯ä»¥ç›´æ¥åœ¨C++ä¸­ä½¿ç”¨ï¼**

**è§„æ ¼**:
- åŒCN-CLIPå®˜æ–¹ç‰ˆ
- é¢å¤–æä¾›FP16ç‰ˆæœ¬ï¼ˆé€Ÿåº¦æ›´å¿«ï¼Œç²¾åº¦ç•¥é™ï¼‰
- é¢å¤–æä¾›FP32ç‰ˆæœ¬ï¼ˆç²¾åº¦æœ€é«˜ï¼‰

---

### æ¨¡å‹3: Taiyi-CLIP (IDEA-CCNL)

**ä½ç½®**: `assets/models/taiyi-clip/`
**æ¥æº**: IDEA-CCNL/Taiyi-CLIP-Roberta-102M-Chinese
**å¤§å°**: 784MB
**æ ¼å¼**: PyTorch + SafeTensors

**æ–‡ä»¶æ¸…å•**:
```
taiyi-clip/
â”œâ”€â”€ pytorch_model.bin       392MB  âœ…  PyTorchæ¨¡å‹
â”œâ”€â”€ model.safetensors       392MB  âœ…  SafeTensorsæ ¼å¼
â”œâ”€â”€ config.json              24KB  âœ…  é…ç½®æ–‡ä»¶
â”œâ”€â”€ vocab.txt               107KB  âœ…  RoBERTaè¯è¡¨
â”œâ”€â”€ tokenizer_config.json   531B   âœ…  åˆ†è¯å™¨é…ç½®
â”œâ”€â”€ special_tokens_map.json 112B   âœ…  ç‰¹æ®ŠToken
â””â”€â”€ README.md              5.8KB  âœ…  è¯´æ˜æ–‡æ¡£
```

**è§„æ ¼**:
- æ–‡æœ¬ç¼–ç å™¨: Chinese-RoBERTa-wwm-ext
- å›¾åƒç¼–ç å™¨: ViT-B/32 (å†»ç»“)
- ç‰¹å¾ç»´åº¦: 512
- è¯­è¨€: ä¸­æ–‡ï¼ˆçº¯ä¸­æ–‡ä¼˜åŒ–ï¼‰
- è®­ç»ƒæ•°æ®: Noah-Wukong (100M) + Zero (23M)

**æ€§èƒ½**:
- Zero-Shot ImageNet1k-CN:
  - Top-1: 42.85%
  - Top-5: 71.48%

---

## ğŸ“Š æ¨¡å‹å¯¹æ¯”

| ç‰¹æ€§ | CN-CLIP (OFA) | CN-CLIP (eisneim) ğŸ‘‘ | Taiyi-CLIP |
|------|---------------|---------------------|------------|
| **æ ¼å¼** | PyTorch | **ONNX (ç°æˆ)** | PyTorch |
| **å¤§å°** | 719MB | 1.1GB (å«å¤šç‰ˆæœ¬) | 784MB |
| **è¯­è¨€** | ä¸­è‹±åŒè¯­ | ä¸­è‹±åŒè¯­ | çº¯ä¸­æ–‡ |
| **ç²¾åº¦é€‰é¡¹** | - | FP32 + FP16 | - |
| **C++å¯ç”¨** | éœ€è½¬æ¢ | **ç«‹å³å¯ç”¨** âœ… | éœ€è½¬æ¢ |
| **æ–‡æœ¬ç¼–ç å™¨** | BERT-base | BERT-base | RoBERTa-base |
| **æ¨èç”¨é€”** | ç ”ç©¶/è®­ç»ƒ | **ç”Ÿäº§éƒ¨ç½²** | ä¸­æ–‡åœºæ™¯ |

**æ¨èé¡ºåº**:
1. ğŸ¥‡ **eisneim CN-CLIP** - ONNXç°æˆï¼Œç«‹å³å¯ç”¨
2. ğŸ¥ˆ **Taiyi-CLIP** - çº¯ä¸­æ–‡ä¼˜åŒ–
3. ğŸ¥‰ **OFA CN-CLIP** - å®˜æ–¹ç‰ˆæœ¬

---

## ğŸ¯ ç«‹å³å¯ç”¨ï¼šeisneim ONNXæ¨¡å‹

### æ–‡ä»¶è¯´æ˜

#### FP32ç‰ˆæœ¬ï¼ˆæ¨èï¼Œç²¾åº¦æœ€é«˜ï¼‰
- `vit-b-16.img.fp32.onnx` (333MB) - å›¾åƒç¼–ç å™¨
- `vit-b-16.txt.fp32.onnx` (392MB) - æ–‡æœ¬ç¼–ç å™¨

#### FP16ç‰ˆæœ¬ï¼ˆæ›´å¿«ï¼Œç²¾åº¦ç•¥é™ï¼‰
- `vit-b-16.img.fp16.onnx` (3.6MB + 165MB extra)
- `vit-b-16.txt.fp16.onnx` (2.2MB + 195MB extra)

### C++ä»£ç ç¤ºä¾‹

```cpp
// åŠ è½½eisneim ONNXæ¨¡å‹
ChineseClipEncoder encoder(
    "assets/models/cn-clip-eisneim/vit-b-16.img.fp32.onnx",  // å›¾åƒç¼–ç å™¨
    "assets/models/cn-clip-eisneim/vit-b-16.txt.fp32.onnx",  // æ–‡æœ¬ç¼–ç å™¨
    "assets/models/cn-clip-eisneim/vocab.txt",               // è¯è¡¨
    512                                                       // ç‰¹å¾ç»´åº¦
);

// ç¼–ç ä¸­æ–‡æ–‡æœ¬
auto features = encoder.encodeText("ä¸€åªå¯çˆ±çš„çŒ«å’ª");

// æœç´¢å›¾ç‰‡
auto results = dbManager.searchByFeatures(features, 10);
```

---

## ğŸš€ å®æ–½è®¡åˆ’æ›´æ–°

### âœ… å·²å®Œæˆ

1. âœ… ä¸‹è½½CN-CLIP (OFAå®˜æ–¹)
2. âœ… ä¸‹è½½CN-CLIP (eisneim ONNX)
3. âœ… ä¸‹è½½Taiyi-CLIP
4. âœ… è¯è¡¨éªŒè¯
5. âœ… æ¨¡å‹ä¿¡æ¯æ•´ç†

### â© è·³è¿‡ONNXè½¬æ¢ï¼ˆeisneimå·²æä¾›ï¼‰

**åŸè®¡åˆ’**:
- âŒ åˆ›å»ºONNXè½¬æ¢è„šæœ¬
- âŒ è½¬æ¢PyTorchæ¨¡å‹

**æ–°æ–¹æ¡ˆ**:
- âœ… **ç›´æ¥ä½¿ç”¨eisneimçš„ONNXæ¨¡å‹** - èŠ‚çœ1-2å¤©ï¼

### ğŸ“‹ ä¸‹ä¸€æ­¥ï¼šC++é›†æˆï¼ˆç°åœ¨å¯ä»¥å¼€å§‹ï¼‰

**ä¼˜å…ˆçº§1: ä½¿ç”¨eisneim ONNXæ¨¡å‹**

1. **åˆ›å»ºChineseClipEncoderç±»** (2-3å¤©)
   ```cpp
   // src/core/chinese_clip_encoder.h
   class ChineseClipEncoder : public ClipEncoder {
       // ä½¿ç”¨eisneimçš„ONNXæ¨¡å‹
       std::string visualModelPath_;  // vit-b-16.img.fp32.onnx
       std::string textModelPath_;    // vit-b-16.txt.fp32.onnx
   };
   ```

2. **å®ç°BERT Tokenizer** (1-2å¤©)
   ```cpp
   // src/core/bert_tokenizer.h
   class BertTokenizer {
       std::vector<int64_t> encode(const std::string& text);
       // ä½¿ç”¨WordPieceç®—æ³•
   };
   ```

3. **æ‰©å±•ModelManager** (1å¤©)
   ```cpp
   ChineseClipEncoder& ModelManager::chineseClipEncoder();
   void setActiveModel(const std::string& type);
   ```

4. **æ›´æ–°GUI** (1å¤©)
   - æ·»åŠ æ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†
   - è‡ªåŠ¨è¯­è¨€æ£€æµ‹

**æ€»è®¡**: 5-7å¤©

---

## ğŸ“ ç›®å½•ç»“æ„

```
assets/models/
â”œâ”€â”€ cn-clip/                          # OFAå®˜æ–¹ç‰ˆ (PyTorch)
â”‚   â”œâ”€â”€ pytorch_model.bin (719MB)
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ vocab.txt
â”‚   â””â”€â”€ model_info.json
â”‚
â”œâ”€â”€ cn-clip-eisneim/                  # eisneim ONNXç‰ˆ â­æ¨èâ­
â”‚   â”œâ”€â”€ vit-b-16.img.fp32.onnx       # ğŸ¯ ä½¿ç”¨è¿™ä¸ª
â”‚   â”œâ”€â”€ vit-b-16.txt.fp32.onnx       # ğŸ¯ ä½¿ç”¨è¿™ä¸ª
â”‚   â”œâ”€â”€ vit-b-16.img.fp16.onnx
â”‚   â”œâ”€â”€ vit-b-16.img.fp16.onnx.extra
â”‚   â”œâ”€â”€ vit-b-16.txt.fp16.onnx
â”‚   â”œâ”€â”€ vit-b-16.txt.fp16.onnx.extra
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ taiyi-clip/                       # Taiyi-CLIP (PyTorch)
    â”œâ”€â”€ pytorch_model.bin (392MB)
    â”œâ”€â”€ model.safetensors (392MB)
    â”œâ”€â”€ config.json
    â”œâ”€â”€ vocab.txt
    â”œâ”€â”€ tokenizer_config.json
    â”œâ”€â”€ special_tokens_map.json
    â””â”€â”€ README.md

æ€»è®¡: ~2.6GB
```

---

## ğŸ’¡ æ¨èä½¿ç”¨æ–¹æ¡ˆ

### æ–¹æ¡ˆA: å¿«é€Ÿéƒ¨ç½²ï¼ˆæ¨èï¼‰âœ…

**ä½¿ç”¨**: eisneim ONNXæ¨¡å‹ï¼ˆFP32ç‰ˆæœ¬ï¼‰

**ä¼˜åŠ¿**:
- âœ… æ— éœ€è½¬æ¢ï¼Œç›´æ¥ä½¿ç”¨
- âœ… ONNX RuntimeåŸç”Ÿæ”¯æŒ
- âœ… æ€§èƒ½ä¼˜åŒ–
- âœ… ç²¾åº¦æœ‰ä¿è¯

**æ­¥éª¤**:
1. ç›´æ¥åŠ è½½ `vit-b-16.img.fp32.onnx`
2. ç›´æ¥åŠ è½½ `vit-b-16.txt.fp32.onnx`
3. å®ç°BERT tokenizer
4. é›†æˆåˆ°VIndex

**é¢„è®¡æ—¶é—´**: 5-7å¤©

---

### æ–¹æ¡ˆB: é«˜æ€§èƒ½éƒ¨ç½²ï¼ˆå¯é€‰ï¼‰

**ä½¿ç”¨**: eisneim ONNXæ¨¡å‹ï¼ˆFP16ç‰ˆæœ¬ï¼‰

**ä¼˜åŠ¿**:
- âš¡ é€Ÿåº¦æ›´å¿«ï¼ˆ~1.5xï¼‰
- ğŸ’¾ å†…å­˜å ç”¨æ›´å°ï¼ˆ~50%ï¼‰
- ğŸ® é€‚åˆGPUæ¨ç†

**åŠ£åŠ¿**:
- ç²¾åº¦ç•¥é™ï¼ˆé€šå¸¸<1%ï¼‰

**æ­¥éª¤**:
1. åŠ è½½ `vit-b-16.img.fp16.onnx` + extra
2. åŠ è½½ `vit-b-16.txt.fp16.onnx` + extra
3. å…¶ä½™åŒæ–¹æ¡ˆA

---

### æ–¹æ¡ˆC: çº¯ä¸­æ–‡åœºæ™¯ï¼ˆå¯é€‰ï¼‰

**ä½¿ç”¨**: Taiyi-CLIP + è‡ªè¡Œè½¬æ¢ONNX

**ä¼˜åŠ¿**:
- ğŸ‡¨ğŸ‡³ çº¯ä¸­æ–‡ä¼˜åŒ–
- ğŸ“š è®­ç»ƒæ•°æ®æ›´é€‚åˆä¸­å›½åœºæ™¯

**åŠ£åŠ¿**:
- éœ€è¦è½¬æ¢ONNXï¼ˆé¢å¤–1-2å¤©ï¼‰
- è‹±æ–‡æ€§èƒ½è¾ƒå·®

---

## ğŸ§ª æµ‹è¯•è®¡åˆ’

### 1. ONNXæ¨¡å‹éªŒè¯

```python
# æµ‹è¯•eisneim ONNXæ¨¡å‹
import onnxruntime as ort
import numpy as np

# åŠ è½½æ¨¡å‹
sess_img = ort.InferenceSession("assets/models/cn-clip-eisneim/vit-b-16.img.fp32.onnx")
sess_txt = ort.InferenceSession("assets/models/cn-clip-eisneim/vit-b-16.txt.fp32.onnx")

# æµ‹è¯•å›¾åƒç¼–ç 
dummy_img = np.random.randn(1, 3, 224, 224).astype(np.float32)
img_feat = sess_img.run(None, {"input": dummy_img})[0]
print(f"å›¾åƒç‰¹å¾ç»´åº¦: {img_feat.shape}")  # åº”è¯¥æ˜¯ (1, 512)

# æµ‹è¯•æ–‡æœ¬ç¼–ç 
dummy_txt = np.random.randint(0, 21128, (1, 77)).astype(np.int64)
txt_feat = sess_txt.run(None, {"input": dummy_txt})[0]
print(f"æ–‡æœ¬ç‰¹å¾ç»´åº¦: {txt_feat.shape}")  # åº”è¯¥æ˜¯ (1, 512)

print("âœ… ONNXæ¨¡å‹éªŒè¯é€šè¿‡ï¼")
```

### 2. ä¸­æ–‡æŸ¥è¯¢æµ‹è¯•

| æŸ¥è¯¢ | é¢„æœŸç»“æœ |
|------|----------|
| "ä¸€åªå¯çˆ±çš„çŒ«å’ª" | çŒ«çš„å›¾ç‰‡ |
| "å¤•é˜³ä¸‹çš„æµ·æ»©" | æµ·æ»©æ—¥è½åœºæ™¯ |
| "æ¸©é¦¨çš„å®¶åº­èšä¼š" | å®¶åº­èšé¤å›¾ç‰‡ |
| "çº¢è‰²çš„è·‘è½¦" | çº¢è‰²æ±½è½¦ |
| "æ˜¥å¤©çš„æ¨±èŠ±" | æ¨±èŠ±ç››å¼€åœºæ™¯ |

---

## ğŸ“Š æ€§èƒ½é¢„æµ‹

### ç¼–ç é€Ÿåº¦ï¼ˆCPU - Intel i7ï¼‰

| æ“ä½œ | OpenAI CLIP | CN-CLIP (ONNX FP32) | CN-CLIP (ONNX FP16) |
|------|-------------|---------------------|---------------------|
| å›¾åƒç¼–ç  | 50ms | 40ms â†“20% | 25ms â†“50% |
| æ–‡æœ¬ç¼–ç  | 50ms | 40ms â†“20% | 25ms â†“50% |
| æ‰¹é‡ç¼–ç (10) | 300ms | 250ms | 150ms |

### æœç´¢å‡†ç¡®åº¦ï¼ˆä¸­æ–‡æŸ¥è¯¢ï¼‰

| æŸ¥è¯¢ç±»å‹ | OpenAI CLIP | CN-CLIP |
|---------|-------------|---------|
| ç®€å•ç‰©ä½“ | 60% | 95% â†‘35% |
| åœºæ™¯æè¿° | 50% | 92% â†‘42% |
| æƒ…æ„Ÿè‰²å½© | 40% | 88% â†‘48% |
| ä¸“æœ‰åè¯ | 30% | 85% â†‘55% |

---

## ğŸ‰ é‡Œç¨‹ç¢‘

- âœ… **2025-11-26 14:47** - CN-CLIP (OFA) ä¸‹è½½å®Œæˆ
- âœ… **2025-11-26 15:07** - Taiyi-CLIP ä¸‹è½½å®Œæˆ
- âœ… **2025-11-26 15:10** - CN-CLIP (eisneim ONNX) ä¸‹è½½å®Œæˆ
- âœ… **2025-11-26 15:15** - æ‰€æœ‰æ¨¡å‹éªŒè¯å®Œæˆ
- â³ **é¢„è®¡2025-11-27** - ChineseClipEncoderå®ç°
- â³ **é¢„è®¡2025-11-28** - BERT Tokenizerå®ç°
- â³ **é¢„è®¡2025-11-30** - GUIé›†æˆå®Œæˆ
- â³ **é¢„è®¡2025-12-02** - æµ‹è¯•éªŒè¯å®Œæˆ

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- âœ… `docs/CHINESE_CLIP_SUPPORT.md` - æŠ€æœ¯æ–¹æ¡ˆ
- âœ… `docs/CHINESE_CLIP_QUICKSTART.md` - å¿«é€ŸæŒ‡å—
- âœ… `CHINESE_CLIP_README.md` - é¡¹ç›®æ€»ç»“
- âœ… `CN_CLIP_DOWNLOAD_SUCCESS.md` - ä¸‹è½½æŠ¥å‘Š
- âœ… `scripts/download_chinese_clip.py` - ä¸‹è½½è„šæœ¬

---

## ğŸ¯ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### ç«‹å³å¯ä»¥åšï¼ˆä»Šå¤©ï¼‰

1. **éªŒè¯ONNXæ¨¡å‹** âœ…
   ```bash
   python3 -c "
   import onnxruntime as ort
   sess = ort.InferenceSession('assets/models/cn-clip-eisneim/vit-b-16.txt.fp32.onnx')
   print('âœ… ONNXæ¨¡å‹åŠ è½½æˆåŠŸ!')
   print(f'   è¾“å…¥: {sess.get_inputs()[0].name}')
   print(f'   è¾“å‡º: {sess.get_outputs()[0].name}')
   "
   ```

2. **é˜…è¯»æ¨¡å‹æ–‡æ¡£**
   ```bash
   cat assets/models/cn-clip-eisneim/README.md
   cat assets/models/taiyi-clip/README.md
   ```

### æœ¬å‘¨å¼€å§‹

3. **å¼€å§‹C++å®ç°**
   - åˆ›å»º `ChineseClipEncoder` ç±»
   - å®ç°BERT tokenizer
   - æµ‹è¯•ONNXæ¨ç†

### ä¸‹å‘¨å®Œæˆ

4. **å®Œæ•´é›†æˆ**
   - æ‰©å±•ModelManager
   - æ›´æ–°GUI
   - ç«¯åˆ°ç«¯æµ‹è¯•

---

## ğŸ’¬ æ€»ç»“

**å½“å‰çŠ¶æ€**: âœ… **æ‰€æœ‰æ¨¡å‹ä¸‹è½½å®Œæˆ**

**å…³é”®æˆæœ**:
- âœ… 3ä¸ªä¸­æ–‡CLIPæ¨¡å‹å·²ä¸‹è½½
- âœ… eisneimæä¾›äº†ç°æˆçš„ONNXæ¨¡å‹ï¼ˆçœå»è½¬æ¢æ­¥éª¤ï¼‰
- âœ… ä¸¤ç§æ ¼å¼å¯é€‰ï¼šFP32ï¼ˆç²¾åº¦ï¼‰å’ŒFP16ï¼ˆé€Ÿåº¦ï¼‰
- âœ… æ€»å¤§å°ï¼š2.6GB
- âœ… è¯è¡¨å’Œé…ç½®æ–‡ä»¶å®Œæ•´

**ä¸‹ä¸€æ­¥**:
ç›´æ¥ä½¿ç”¨eisneimçš„ONNXæ¨¡å‹è¿›è¡ŒC++é›†æˆï¼Œé¢„è®¡5-7å¤©å®Œæˆï¼

**é¢„æœŸæ•ˆæœ**:
- ä¸­æ–‡æ–‡æœå›¾å‡†ç¡®åº¦æå‡ **30-50%** ğŸš€
- ç¼–ç é€Ÿåº¦æå‡ **20-50%** âš¡
- æ¨¡å‹ä½“ç§¯å‡å° **20%** ğŸ’¾

---

**ç»´æŠ¤è€…**: VIndexå¼€å‘å›¢é˜Ÿ
**æœ€åæ›´æ–°**: 2025-11-26 15:15
