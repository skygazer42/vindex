#!/usr/bin/env python3
"""
éªŒè¯ä¸‹è½½çš„ONNXæ¨¡å‹
æµ‹è¯•CN-CLIP (eisneim) çš„ONNXæ¨¡å‹æ˜¯å¦å¯ä»¥æ­£å¸¸åŠ è½½å’Œæ¨ç†
"""

import sys
from pathlib import Path
import numpy as np

try:
    import onnxruntime as ort
except ImportError:
    print("âŒ onnxruntimeæœªå®‰è£…")
    print("   å®‰è£…: pip install onnxruntime")
    sys.exit(1)


def print_header(text):
    print("\n" + "=" * 60)
    print(f"  {text}")
    print("=" * 60)


def verify_model(model_path, input_shape=None, input_name="input"):
    """éªŒè¯ONNXæ¨¡å‹"""
    try:
        # åŠ è½½æ¨¡å‹
        print(f"\nğŸ“¥ åŠ è½½æ¨¡å‹: {model_path.name}")
        sess = ort.InferenceSession(str(model_path))

        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        inputs = sess.get_inputs()
        outputs = sess.get_outputs()

        print(f"   è¾“å…¥æ•°é‡: {len(inputs)}")
        for inp in inputs:
            print(f"     - {inp.name}: {inp.shape} ({inp.type})")

        print(f"   è¾“å‡ºæ•°é‡: {len(outputs)}")
        for out in outputs:
            print(f"     - {out.name}: {out.shape} ({out.type})")

        # å¦‚æœæœªæä¾›input_shapeï¼Œä»æ¨¡å‹è¾“å…¥è‡ªåŠ¨æ¨æ–­
        if input_shape is None:
            # è·å–æ¨¡å‹æœŸæœ›çš„è¾“å…¥å½¢çŠ¶
            input_shape_from_model = inputs[0].shape
            # æ›¿æ¢åŠ¨æ€ç»´åº¦ï¼ˆå¦‚batch_sizeï¼‰ä¸º1
            input_shape = tuple(1 if isinstance(dim, str) else dim for dim in input_shape_from_model)
            print(f"   è‡ªåŠ¨æ¨æ–­è¾“å…¥å½¢çŠ¶: {input_shape}")

        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        if inputs[0].type == 'tensor(float)':
            dummy_input = np.random.randn(*input_shape).astype(np.float32)
        else:
            dummy_input = np.random.randint(0, 21128, input_shape).astype(np.int64)

        # æ¨ç†æµ‹è¯•
        print(f"   ğŸ”„ æµ‹è¯•æ¨ç†...")
        input_dict = {inputs[0].name: dummy_input}
        result = sess.run(None, input_dict)

        print(f"   âœ… æ¨ç†æˆåŠŸ!")
        print(f"   è¾“å‡ºå½¢çŠ¶: {result[0].shape}")
        print(f"   è¾“å‡ºèŒƒå›´: [{result[0].min():.4f}, {result[0].max():.4f}]")

        return True, sess

    except Exception as e:
        print(f"   âŒ å¤±è´¥: {e}")
        return False, None


def verify_cn_clip_onnx():
    """éªŒè¯CN-CLIP ONNXæ¨¡å‹"""
    print_header("ğŸŒ éªŒè¯ CN-CLIP ONNX æ¨¡å‹")

    base_path = Path("../assets/models/cn-clip-eisneim")

    if not base_path.exists():
        print(f"âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {base_path}")
        return False

    print(f"ğŸ“‚ æ¨¡å‹ç›®å½•: {base_path.absolute()}")

    results = {}

    # æµ‹è¯•å›¾åƒç¼–ç å™¨ (FP32)
    print("\n" + "-" * 60)
    print("æµ‹è¯• 1: å›¾åƒç¼–ç å™¨ (FP32)")
    print("-" * 60)
    img_fp32_path = base_path / "vit-b-16.img.fp32.onnx"
    if img_fp32_path.exists():
        success, sess = verify_model(img_fp32_path, (1, 3, 224, 224))
        results['img_fp32'] = success
    else:
        print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {img_fp32_path}")
        results['img_fp32'] = False

    # æµ‹è¯•æ–‡æœ¬ç¼–ç å™¨ (FP32)
    print("\n" + "-" * 60)
    print("æµ‹è¯• 2: æ–‡æœ¬ç¼–ç å™¨ (FP32)")
    print("-" * 60)
    txt_fp32_path = base_path / "vit-b-16.txt.fp32.onnx"
    if txt_fp32_path.exists():
        # è‡ªåŠ¨æ¨æ–­æ­£ç¡®çš„è¾“å…¥å½¢çŠ¶
        success, sess = verify_model(txt_fp32_path, input_shape=None)
        results['txt_fp32'] = success
    else:
        print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {txt_fp32_path}")
        results['txt_fp32'] = False

    # æµ‹è¯•å›¾åƒç¼–ç å™¨ (FP16)
    print("\n" + "-" * 60)
    print("æµ‹è¯• 3: å›¾åƒç¼–ç å™¨ (FP16)")
    print("-" * 60)
    img_fp16_path = base_path / "vit-b-16.img.fp16.onnx"
    if img_fp16_path.exists():
        success, sess = verify_model(img_fp16_path, (1, 3, 224, 224))
        results['img_fp16'] = success
    else:
        print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {img_fp16_path}")
        results['img_fp16'] = False

    # æµ‹è¯•æ–‡æœ¬ç¼–ç å™¨ (FP16)
    print("\n" + "-" * 60)
    print("æµ‹è¯• 4: æ–‡æœ¬ç¼–ç å™¨ (FP16)")
    print("-" * 60)
    txt_fp16_path = base_path / "vit-b-16.txt.fp16.onnx"
    if txt_fp16_path.exists():
        # è‡ªåŠ¨æ¨æ–­æ­£ç¡®çš„è¾“å…¥å½¢çŠ¶
        success, sess = verify_model(txt_fp16_path, input_shape=None)
        results['txt_fp16'] = success
    else:
        print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {txt_fp16_path}")
        results['txt_fp16'] = False

    return results


def print_summary(results):
    """æ‰“å°æµ‹è¯•æ€»ç»“"""
    print_header("ğŸ“Š æµ‹è¯•æ€»ç»“")

    total = len(results)
    passed = sum(1 for v in results.values() if v)

    print(f"\næ€»è®¡: {total} ä¸ªæ¨¡å‹")
    print(f"é€šè¿‡: {passed} ä¸ª âœ…")
    print(f"å¤±è´¥: {total - passed} ä¸ª âŒ")
    print()

    for name, success in results.items():
        status = "âœ…" if success else "âŒ"
        print(f"  {status} {name}")

    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æ¨¡å‹éªŒè¯é€šè¿‡ï¼å¯ä»¥å¼€å§‹C++é›†æˆã€‚")
        return True
    else:
        print("\nâš ï¸  éƒ¨åˆ†æ¨¡å‹éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ã€‚")
        return False


def main():
    print("ğŸ” ONNXæ¨¡å‹éªŒè¯å·¥å…·")
    print()

    # éªŒè¯CN-CLIP ONNXæ¨¡å‹
    results = verify_cn_clip_onnx()

    # æ‰“å°æ€»ç»“
    all_passed = print_summary(results)

    # æ¨èä¸‹ä¸€æ­¥
    if all_passed:
        print_header("ğŸš€ ä¸‹ä¸€æ­¥")
        print("""
æ¨èä½¿ç”¨FP32ç‰ˆæœ¬è¿›è¡Œå¼€å‘ï¼ˆç²¾åº¦æœ€é«˜ï¼‰ï¼š

C++ä»£ç ç¤ºä¾‹ï¼š
    ChineseClipEncoder encoder(
        "assets/models/cn-clip-eisneim/vit-b-16.img.fp32.onnx",
        "assets/models/cn-clip-eisneim/vit-b-16.txt.fp32.onnx",
        "assets/models/cn-clip/vocab.txt",
        512
    );

å¦‚éœ€æ›´å¿«é€Ÿåº¦ï¼Œå¯ä½¿ç”¨FP16ç‰ˆæœ¬ï¼ˆç²¾åº¦ç•¥é™<1%ï¼‰ï¼š
    ChineseClipEncoder encoder(
        "assets/models/cn-clip-eisneim/vit-b-16.img.fp16.onnx",
        "assets/models/cn-clip-eisneim/vit-b-16.txt.fp16.onnx",
        "assets/models/cn-clip/vocab.txt",
        512
    );
        """)

    sys.exit(0 if all_passed else 1)


if __name__ == "__main__":
    main()
